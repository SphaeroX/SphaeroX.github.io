<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <title>OpenAI Realtime Audio Demo</title>
</head>

<body>
    <h1>OpenAI Realtime Audio Demo</h1>

    <label for="apiKey">API Key:</label>
    <input type="text" id="apiKey" placeholder="OPENAI_API_KEY" /><br><br>

    <label for="orgId">Organization ID (optional):</label>
    <input type="text" id="orgId" placeholder="OPENAI_ORG_ID" /><br><br>

    <label for="projectId">Project ID (optional):</label>
    <input type="text" id="projectId" placeholder="OPENAI_PROJECT_ID" /><br><br>

    <button id="connectBtn">Verbinden</button>

    <hr>
    <label for="userText">Nachricht:</label>
    <input type="text" id="userText" placeholder="Dein Text..." />
    <button id="sendBtn">Senden</button>

    <script>
        // comments in English
        let ws = null;

        // Audio context to play PCM16 data
        const audioContext = new AudioContext({ sampleRate: 16000 });

        // Helper function to convert base64 PCM16 -> AudioBuffer -> play
        async function playPCM16Chunk(base64Chunk) {
            const binaryString = atob(base64Chunk);
            const len = binaryString.length;
            const buffer16 = new Int16Array(len / 2);

            for (let i = 0; i < len; i += 2) {
                const lower = binaryString.charCodeAt(i);
                const higher = binaryString.charCodeAt(i + 1);
                const value = (higher << 8) | lower;
                buffer16[i / 2] = value < 32768 ? value : value - 65536;
            }

            const float32 = new Float32Array(buffer16.length);
            for (let i = 0; i < buffer16.length; i++) {
                float32[i] = buffer16[i] / 32768;
            }

            const audioBuffer = audioContext.createBuffer(1, float32.length, 16000);
            audioBuffer.copyToChannel(float32, 0);

            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.start();
        }

        // Connect to OpenAI Realtime WebSocket
        document.getElementById("connectBtn").onclick = () => {
            const OPENAI_API_KEY = document.getElementById("apiKey").value.trim();
            const OPENAI_ORG_ID = document.getElementById("orgId").value.trim();
            const OPENAI_PROJECT_ID = document.getElementById("projectId").value.trim();

            if (!OPENAI_API_KEY) {
                alert("Bitte einen API Key eingeben!");
                return;
            }

            const protocols = [
                "realtime",
                "openai-insecure-api-key." + OPENAI_API_KEY,
                "openai-beta.realtime-v1"
            ];
            if (OPENAI_ORG_ID) {
                protocols.push("openai-organization." + OPENAI_ORG_ID);
            }
            if (OPENAI_PROJECT_ID) {
                protocols.push("openai-project." + OPENAI_PROJECT_ID);
            }

            ws = new WebSocket(
                "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17",
                protocols
            );

            ws.onopen = () => {
                console.log("Connected to server.");
                alert("WebSocket Verbindung hergestellt!");
            };

            ws.onmessage = (event) => {
                const msg = JSON.parse(event.data);
                // Only handle audio streaming
                if (msg.type === "response.audio.delta") {
                    playPCM16Chunk(msg.delta);
                }
            };

            ws.onerror = (err) => {
                console.error("WebSocket error:", err);
                alert("Fehler bei der WebSocket-Verbindung (siehe Konsole).");
            };

            ws.onclose = () => {
                console.log("WebSocket closed.");
                alert("WebSocket Verbindung geschlossen!");
            };
        };

        // Send a simple user message and request an audio response
        document.getElementById("sendBtn").onclick = () => {
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                alert("WebSocket nicht verbunden!");
                return;
            }
            const text = document.getElementById('userText').value.trim();
            if (!text) {
                alert("Bitte Text eingeben!");
                return;
            }

            // conversation.item.create
            const userMsgId = "msg_" + Date.now();
            const createItemEvent = {
                event_id: "event_" + Date.now(),
                type: "conversation.item.create",
                previous_item_id: null,
                item: {
                    id: userMsgId,
                    type: "message",
                    role: "user",
                    content: [
                        {
                            type: "input_text",
                            text: text
                        }
                    ]
                }
            };
            ws.send(JSON.stringify(createItemEvent));

            // response.create: request audio
            const createResponseEvent = {
                event_id: "event_" + (Date.now() + 1),
                type: "response.create",
                response: {
                    modalities: ["audio"],
                    instructions: "Bitte nur als Audio antworten."
                }
            };
            ws.send(JSON.stringify(createResponseEvent));
        };
    </script>
</body>

</html>